{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7fdca11",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "import sklearn\n",
    "from sklearn.covariance import LedoitWolf, OAS, MinCovDet\n",
    "from scipy.stats import wasserstein_distance\n",
    "import math\n",
    "import transformers\n",
    "import textattack\n",
    "from textattack.datasets import HuggingFaceDataset\n",
    "from textattack.goal_functions import UntargetedClassification\n",
    "from textattack.models.wrappers import HuggingFaceModelWrapper\n",
    "from textattack.search_methods import GreedySearch\n",
    "from textattack.constraints.pre_transformation import (\n",
    "    RepeatModification,\n",
    "    StopwordModification,\n",
    ")\n",
    "from textattack import Attack\n",
    "from textattack.transformations import WordSwap\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd64053a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_train_data(name=\"ag_news\"):\n",
    "    dataset = load_dataset(name).shuffle(seed=0)\n",
    "    num_labels = dataset[\"train\"].features[\"label\"].num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aedb0069",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dfefc85b3f141fe9a025b2e8d35444b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1780.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9959583c65534fb8a7264ff0faeb2ee5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1227.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading and preparing dataset ag_news/default (download: 29.88 MiB, generated: 30.23 MiB, post-processed: Unknown size, total: 60.10 MiB) to /home/onyxia/.cache/huggingface/datasets/ag_news/default/0.0.0/0eeeaaa5fb6dffd81458e293dfea1adba2881ffcbdc3fb56baeb5a892566c29a...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f3f8aea37f043cba72e6198324e64eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=11045148.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9f6402b5e1b4786a7016d47374290f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=751209.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ag_news downloaded and prepared to /home/onyxia/.cache/huggingface/datasets/ag_news/default/0.0.0/0eeeaaa5fb6dffd81458e293dfea1adba2881ffcbdc3fb56baeb5a892566c29a. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 120000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 7600\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"ag_news\")\n",
    "num_labels = 4\n",
    "# dataset.shuffle(seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cadd60",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Etapes du Projet:\n",
    "\n",
    "A. RECUPERER LES DONNEES\n",
    "1. Récupérer les données:\\\n",
    "    a. Récupérer les csv -> Fait\\\n",
    "    b. On n'a que des attaques/données qui ont été attaquées, récupérer d'autres données random ou se              contenter de ça?\n",
    "2. Récupérer BERT -> à Faire\n",
    "\n",
    "B. Preprocessing\n",
    "1. Data cleaning (drop duplicates, supprimer les attaques qui sont les mêmes que le text de base, etc...à\n",
    "2. Tokenizer\n",
    "3. Réduire la dimension\n",
    "\n",
    "C. COMPARER LES MODELES\n",
    "1. Aller à l'intérieur de BERT\n",
    "2. Coder les différents scores (Manhalobis, max(softmax), KL(softmax,uniform), éventuellement d'autres options qu'on veut test)\n",
    "3. Calculer les seuils (par exemple set False Positive Rate à 10%, c'est ce qu'ils font pour Manhalobis)\n",
    "4. Montrer les résultats (ROC, TPR, TNR, Confusion Matrix, etc...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3519ed0",
   "metadata": {},
   "source": [
    "Description étape par étape du code Mahalanobis:\\\n",
    "STRUCTURE FINALE : (structure du main)\\\n",
    "1.\tPrérequis (déjà faits)\\\n",
    "a.\tCharge le modèle\\\n",
    "b.\tTokenize\\\n",
    "2.\tPremier load :\\\n",
    "a.\tRécupère data[‘train’]\\\n",
    "b.\tEn récupère 90% (10% de valset non utilisé)\\\n",
    "c.\tRécupère les train_features dessus (ie dataset où data[label 1] = outputs(layer) qui ont mené au label 1)\\\n",
    "d.\tOn preprocess\\\n",
    "e.\tOn récupère mean,cov \\\n",
    "3.\tDeuxième load :\\\n",
    "a.\tOn récupère un testset qui contient des phrases et attaque ou pas attaque\\\n",
    "b.\tOn récupère test_features (et préprocess) (qui contient les layers, à partir de testset[‘text’]\\ \n",
    "c.\tOn calcul leur distance de mahalan (pour chaque estimateur) avec la mean,cov du train\\\n",
    "d.\tOn calcul la confidence (découle de mahalan, MLE)\\\n",
    "e.\tOn calcul le seuil de conf % fpr sur le TEST SET (fonction sklearn roc_curve, fonction un peu chelou à capter)\\\n",
    "f.\tOn affiche les autres métriques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b2452b",
   "metadata": {},
   "source": [
    "#### Global Variables:\n",
    "1. \n",
    "batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6ea219",
   "metadata": {},
   "source": [
    "## The idea:\n",
    "predictor : $\\mathbb{1}_{attack} = \\mathbb{1}_{dist>threshold}$\\\n",
    "with $threshold$ such that $P($attack is predicted$|$not attack$)=0.1$\\\n",
    "$\\begin{itemize}\n",
    "\\item Compute manhalobis distance -> we need x, mu, and sigma\\\n",
    "to get sigma we estimate cov matrix on train set -> we need output.hs\n",
    "\\item Compute threshold\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94ae5b0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>perturbed_text</th>\n",
       "      <th>original_score</th>\n",
       "      <th>perturbed_score</th>\n",
       "      <th>original_output</th>\n",
       "      <th>perturbed_output</th>\n",
       "      <th>ground_truth_output</th>\n",
       "      <th>num_queries</th>\n",
       "      <th>result_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fears for T [[N]] pension after talks Unions r...</td>\n",
       "      <td>Fears for T [[pl]] pension after talks Unions ...</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.613322</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Race is [[On]]: [[Second]] Private Team Se...</td>\n",
       "      <td>The Race is [[over]]: [[private]] Private Team...</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.000980</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>Failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ky. Company Wins Grant to Study Peptides (AP) ...</td>\n",
       "      <td>Ky. Company Wins Grant to Study Peptides (AP) ...</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>Failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prediction Unit Helps [[Forecast]] Wildfires (...</td>\n",
       "      <td>Prediction Unit Helps [[forecast]] Wildfires (...</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>0.017141</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>Failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Calif. Aims to Limit Farm-Related Smog (AP) [[...</td>\n",
       "      <td>Calif. Aims to Limit Farm-Related Smog (AP) [[...</td>\n",
       "      <td>0.000951</td>\n",
       "      <td>0.162635</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>Failed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       original_text  \\\n",
       "0  Fears for T [[N]] pension after talks Unions r...   \n",
       "1  The Race is [[On]]: [[Second]] Private Team Se...   \n",
       "2  Ky. Company Wins Grant to Study Peptides (AP) ...   \n",
       "3  Prediction Unit Helps [[Forecast]] Wildfires (...   \n",
       "4  Calif. Aims to Limit Farm-Related Smog (AP) [[...   \n",
       "\n",
       "                                      perturbed_text  original_score  \\\n",
       "0  Fears for T [[pl]] pension after talks Unions ...        0.000575   \n",
       "1  The Race is [[over]]: [[private]] Private Team...        0.000504   \n",
       "2  Ky. Company Wins Grant to Study Peptides (AP) ...        0.000354   \n",
       "3  Prediction Unit Helps [[forecast]] Wildfires (...        0.000628   \n",
       "4  Calif. Aims to Limit Farm-Related Smog (AP) [[...        0.000951   \n",
       "\n",
       "   perturbed_score  original_output  perturbed_output  ground_truth_output  \\\n",
       "0         0.613322              2.0               3.0                  2.0   \n",
       "1         0.000980              3.0               3.0                  3.0   \n",
       "2         0.000449              3.0               3.0                  3.0   \n",
       "3         0.017141              3.0               3.0                  3.0   \n",
       "4         0.162635              3.0               3.0                  3.0   \n",
       "\n",
       "   num_queries result_type  \n",
       "0         84.0  Successful  \n",
       "1        178.0      Failed  \n",
       "2        148.0      Failed  \n",
       "3        139.0      Failed  \n",
       "4         52.0      Failed  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bae.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee507adb",
   "metadata": {},
   "source": [
    "## A. Récupération des données et du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf607d47",
   "metadata": {},
   "source": [
    "### A.1 Récupération des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "746391e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_bae = pd.read_csv(\"bae.csv\")\n",
    "df_pwws = pd.read_csv(\"pwws.csv\")\n",
    "df_textfooler = pd.read_csv(\"textfooler.csv\")\n",
    "df_tf = pd.read_csv(\"tf-adj.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "daa5a090",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Failed        0.815395\n",
       "Successful    0.136053\n",
       "Skipped       0.048553\n",
       "Name: result_type, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bae.result_type.value_counts(1)\n",
    "# Some attacks are skipped for unknown reasons as of now, \\\n",
    "# in those cases there are no attacks and the perturbed text is the original text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8b03f3",
   "metadata": {},
   "source": [
    "### A.2 Récupération du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebae8089",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd7699aaa984415ea068c618a81a3bac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=706.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea12a65391524418b2d51c166a678ef4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=437991539.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d034846e33f34d27a0e61b069c157a7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Unknown if model of class <class 'transformers.models.bert.modeling_bert.BertForSequenceClassification'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (/home/onyxia/.cache/huggingface/datasets/ag_news/default/0.0.0/0eeeaaa5fb6dffd81458e293dfea1adba2881ffcbdc3fb56baeb5a892566c29a)\n",
      "textattack: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mag_news\u001b[0m, split \u001b[94mtest\u001b[0m.\n"
     ]
    }
   ],
   "source": [
    "model = transformers.AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"textattack/bert-base-uncased-ag-news\"\n",
    ")\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    \"textattack/bert-base-uncased-ag-news\"\n",
    ")\n",
    "\n",
    "model_wrapper = HuggingFaceModelWrapper(model, tokenizer)\n",
    "goal_function = UntargetedClassification(model_wrapper)\n",
    "dataset = HuggingFaceDataset(\"ag_news\", None, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a1800b",
   "metadata": {},
   "source": [
    "### Accessing BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cd568e",
   "metadata": {},
   "source": [
    "Guide du github pour pénétrer BERT:\\\n",
    "Méthodes de réduction de dimension dans utils.miscelaneous\\\n",
    "pénétration dans utils.detection\n",
    "\n",
    "layer = -1\\\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4478e03b",
   "metadata": {},
   "source": [
    "class model:\n",
    "    def __init__(self,data,):\n",
    "        self.data = data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c7f1e054",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_BERT(series, batch_size=10, output_hs=False, output_attentions=False):\n",
    "    # We choose to run by batches to avoid kernel death\n",
    "    tokens = tokenizer(\n",
    "        series.tolist(),\n",
    "        max_length=256,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        add_special_tokens=True,\n",
    "        return_attention_mask=True,\n",
    "    )\n",
    "    num_batches = (len(series) - 1) // batch_size + 1\n",
    "    Outputs = []\n",
    "    for batch_idx in range(num_batches):  # Next line can probably be coded way cleaner\n",
    "        window = [batch_idx * batch_size, (batch_idx + 1) * batch_size]\n",
    "        Outputs.append(\n",
    "            model(\n",
    "                input_ids=tokens[\"input_ids\"][window[0] : window[1]],\n",
    "                attention_mask=tokens[\"attention_mask\"][window[0] : window[1]],\n",
    "                token_type_ids=tokens[\"token_type_ids\"][window[0] : window[1]],\n",
    "                output_hidden_states=output_hs,\n",
    "                output_attentions=output_attentions,\n",
    "            )\n",
    "        )\n",
    "    return Outputs\n",
    "    # Outputs = torch.cat(outputs)\n",
    "    # return Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b60fbe8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'run_BERT' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f779de615e18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_BERT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_hs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'run_BERT' is not defined"
     ]
    }
   ],
   "source": [
    "outputs = run_BERT(series[:11], output_hs=True, output_attentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "92e68560",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Idée : à terme tout mettre dans une classe, mettre des if last_layer : last_layer.append, etc...\n",
    "# Et définir au début: if method = Manhalobis, set last_layer = True, etc...\n",
    "def get_features(Outputs):\n",
    "    # We wish to isolate a dataset containing in X the Manhalobis distance, and in Y the prediction\n",
    "    last_layer = []\n",
    "    pred = []\n",
    "    softmax = []\n",
    "    num_batches = len(Outputs)\n",
    "    for batch_idx in range(num_batches):\n",
    "        last_layer.append(Outputs[batch_idx].hidden_states[-1][:, 0, :])\n",
    "        pred.append(Outputs[batch_idx].logits.argmax(1))\n",
    "        softmax.append(torch.softmax(Outputs[batch_idx].logits, dim=1))\n",
    "    last_layer = torch.cat(last_layer)\n",
    "    pred = torch.cat(pred)\n",
    "    softmax = torch.cat(softmax)\n",
    "    return last_layer, pred, softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "1c8b4d17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "last_layer, pred, softmax = get_features(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "03a13407",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_cov_estimator(x, name):\n",
    "    if name == \"LW\":\n",
    "        print(LedoitWolf().fit(x).shrinkage_)\n",
    "        print(LedoitWolf().fit(x).mahalanobis(y.numpy().reshape(1, -1)))\n",
    "        return LedoitWolf().fit(x).covariance_\n",
    "    if name == \"empirical\":\n",
    "        return np.cov(x.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "be37662c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_mean_cov(last_layer, cov_estimator=\"empirical\"):\n",
    "    mean = last_layer.mean(0)\n",
    "    cov = torch.Tensor(get_cov_estimator(last_layer.detach().numpy(), cov_estimator))\n",
    "    return mean, cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "a9d11512",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.510341562552002\n",
      "[4533.74696871]\n"
     ]
    }
   ],
   "source": [
    "mean, cov = get_mean_cov(last_layer, cov_estimator=\"LW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "9be95ec1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mahalanobis(x, mean, cov):\n",
    "    inv_cov = torch.inverse(cov)\n",
    "    dist = (x - mean).T @ inv_cov @ (x - mean)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "e4b9a2dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4533.7480, grad_fn=<DotBackward>)"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y = torch.rand(768)\n",
    "manhalobis(y, mean, cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5de6895",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "676d7b4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-526-e08f3babd0a8>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-526-e08f3babd0a8>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    def get_roc(thresh)\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def get_roc(thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a7d7ac",
   "metadata": {},
   "source": [
    "Reste à faire : comprendre ce qu'ils font avec les labels dans train_features, c'est là-dessus qu'ils calculent cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0ea6b518",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6506667137145996\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "series = df_bae.original_text\n",
    "Outputs = run_BERT(to_run[:8], output_hs=True)\n",
    "print(time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "21b86b6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 256, 768])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0].hidden_states[12].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d068f50",
   "metadata": {},
   "source": [
    "Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe23729f",
   "metadata": {
    "tags": []
   },
   "source": [
    "outputs = []\n",
    "for idx in tqdm(range(2)):\n",
    "    outputs.append(model(**tokenizer(to_run[idx*10:(idx+1)*10],max_length=256,return_tensors='pt',truncation=True,padding=\"max_length\",\\\n",
    "          add_special_tokens=True,return_attention_mask=True)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a06ce81c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 768])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.hidden_states[-1][:, 0, :].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04258f06",
   "metadata": {},
   "source": [
    "a.attentions de shape 12\\*batch_size\\*12\\*256\\*256\\\n",
    "a.hidden_states de shape 13\\*batch_size\\*256\\*768 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b48420",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-d57c852c358c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdf_bae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moriginal_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0motp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_bae\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0motp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'output' is not defined"
     ]
    }
   ],
   "source": [
    "mask = output.logits.argmax(1).tolist() != df_bae.original_output[:100]\n",
    "otp = df_bae[:100][mask]\n",
    "otp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e457d46",
   "metadata": {},
   "source": [
    "-> Nos misclassifications sont plus grandes que le BERT qu'ils utilisent -> notre modèle est moins bon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b724f844",
   "metadata": {},
   "source": [
    "### Méthode de classification des attaques\n",
    "Pour l'instant pseudo-code dégueulasse pour structurer la pensée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "8e7af8d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DetectionMethods:\n",
    "    def __init__(self, method, attacks):\n",
    "        ### Inputs:\n",
    "        # method : distance used\n",
    "        # attacks : a dataframe containing text, desired_output, and whether it's an attack or not\n",
    "        self.method = method\n",
    "        self.attacks = attacks\n",
    "\n",
    "    def get_model_output(self):\n",
    "        self.model_output = torch.softmax(\n",
    "            model(\n",
    "                **tokenizer(\n",
    "                    self.attacks.text.tolist(), return_tensors=\"pt\", padding=True\n",
    "                )\n",
    "            ).logits,\n",
    "            dim=1,\n",
    "        )\n",
    "\n",
    "    def get_distance(self):\n",
    "        if self.method == \"Max_softmax\":\n",
    "            return np.max(self.model_output, axis=0)\n",
    "        if self.method == \"Kullback-Leibler\":\n",
    "            # TODO\n",
    "            return\n",
    "        if self.method == \"Wasserstein\":\n",
    "            # Ca coûte rien de le rajouter hehe\n",
    "            return wasserstein_distance(self.model_output, [0.25] * 4)\n",
    "        if self.method == \"My_Method\":\n",
    "            # TODO\n",
    "            sorted_output = np.argsort(self.model_output, axis=0)\n",
    "            return sorted_output[-1] - sorted_output[-2]\n",
    "        if self.method == \"Manhalobis\":\n",
    "            # TODO\n",
    "            return\n",
    "\n",
    "    def get_FPR(classifier):\n",
    "        ### Computes FPR score\n",
    "        return FPR_score\n",
    "\n",
    "    def set_threshold(target=0.10, error=1e-5, n_iter=20):\n",
    "        ### Finds by dichotomy a distance threshold such that the FPR equals a certain target (usually 10%)\n",
    "        threshold = 0.5\n",
    "        t_min = 0\n",
    "        t_max = 1\n",
    "        for iter in range(n_iter):\n",
    "            FPR = self.FPR(classifier(threshold))\n",
    "            if abs(FPR - target) > 1e-5:\n",
    "                self.threshold = threshold\n",
    "                return f\"Successful convergence, threshold set to {self.threshold}\"\n",
    "            if FPR < 0.1:\n",
    "                t_min = threshold\n",
    "                threshold = (threshold + t_max) / 2\n",
    "            else:\n",
    "                t_max = threshold\n",
    "                threshold = (threshold + t_min) / 2\n",
    "        self.threshold = threshold\n",
    "        return f\"No convergence after {n_iter} iterations, threshold set to {self.threshold}, FPR = {FPR}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "da695cf6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_BERT(series, batch_size=10, output_hs=False, output_attentions=False):\n",
    "    # We choose to run by batches to avoid kernel death\n",
    "    tokens = tokenizer(\n",
    "        series.tolist(),\n",
    "        max_length=256,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        add_special_tokens=True,\n",
    "        return_attention_mask=True,\n",
    "    )\n",
    "    num_batches = (len(series) - 1) // batch_size + 1\n",
    "    Outputs = []\n",
    "    for batch_idx in range(num_batches):  # Next line can probably be coded way cleaner\n",
    "        window = [batch_idx * batch_size, (batch_idx + 1) * batch_size]\n",
    "        Outputs.append(\n",
    "            model(\n",
    "                input_ids=tokens[\"input_ids\"][window[0] : window[1]],\n",
    "                attention_mask=tokens[\"attention_mask\"][window[0] : window[1]],\n",
    "                token_type_ids=tokens[\"token_type_ids\"][window[0] : window[1]],\n",
    "                output_hidden_states=output_hs,\n",
    "                output_attentions=output_attentions,\n",
    "            )\n",
    "        )\n",
    "    return Outputs\n",
    "    # Outputs = torch.cat(outputs)\n",
    "    # return Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "2f21284f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outputs = run_BERT(series[:11], output_hs=True, output_attentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "f4c1ffaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Idée : à terme tout mettre dans une classe, mettre des if last_layer : last_layer.append, etc...\n",
    "# Et définir au début: if method = Manhalobis, set last_layer = True, etc...\n",
    "def get_features(Outputs):\n",
    "    # We wish to isolate a dataset containing in X the Manhalobis distance, and in Y the prediction\n",
    "    last_layer = []\n",
    "    pred = []\n",
    "    softmax = []\n",
    "    num_batches = len(Outputs)\n",
    "    for batch_idx in range(num_batches):\n",
    "        last_layer.append(Outputs[batch_idx].hidden_states[-1][:, 0, :])\n",
    "        pred.append(Outputs[batch_idx].logits.argmax(1))\n",
    "        softmax.append(torch.softmax(Outputs[batch_idx].logits, dim=1))\n",
    "    last_layer = torch.cat(last_layer)\n",
    "    pred = torch.cat(pred)\n",
    "    softmax = torch.cat(softmax)\n",
    "    return last_layer, pred, softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "5c0b1c41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "last_layer, pred, softmax = get_features(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "a8000728",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_cov_estimator(x, name):\n",
    "    if name == \"LW\":\n",
    "        print(LedoitWolf().fit(x).shrinkage_)\n",
    "        print(LedoitWolf().fit(x).mahalanobis(y.numpy().reshape(1, -1)))\n",
    "        return LedoitWolf().fit(x).covariance_\n",
    "    if name == \"empirical\":\n",
    "        return np.cov(x.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "38285b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5654e-22)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_mean_cov(x.T, estimator=\"MCD\")[1].det()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "8b54e6f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mahalanobis(x, mean, cov):\n",
    "    inv_cov = torch.inverse(cov)\n",
    "    dist = (x - mean).T @ inv_cov @ (x - mean)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "3e7f0370",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4533.7480, grad_fn=<DotBackward>)"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y = torch.rand(768)\n",
    "manhalobis(y, mean, cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cbb832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "1f0dc47d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-526-e08f3babd0a8>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-526-e08f3babd0a8>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    def get_roc(thresh)\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def get_roc(thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70ff0bb",
   "metadata": {},
   "source": [
    "# FIRST TRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8639321a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class project:\n",
    "    load_model\n",
    "    tokenize\n",
    "    run_model\n",
    "    get_data(type=train or type=test)\n",
    "    get_features (existe déjà)\n",
    "    preprocess (reduce_dim)\n",
    "    get_mean_cov    \n",
    "    get_attack_data\n",
    "    get_score (implique mala)\n",
    "    get_roc_curve(fpr_thresh=)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f05e4e",
   "metadata": {},
   "source": [
    "### Step 1: Loading the model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88c1007f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transformers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-ea96135c4b1e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAutoModelForSequenceClassification\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"textattack/bert-base-uncased-ag-news\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAutoTokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"textattack/bert-base-uncased-ag-news\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel_wrapper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mHuggingFaceModelWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mgoal_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUntargetedClassification\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_wrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'transformers' is not defined"
     ]
    }
   ],
   "source": [
    "model = transformers.AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"textattack/bert-base-uncased-ag-news\"\n",
    ")\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    \"textattack/bert-base-uncased-ag-news\"\n",
    ")\n",
    "\n",
    "model_wrapper = HuggingFaceModelWrapper(model, tokenizer)\n",
    "goal_function = UntargetedClassification(model_wrapper)\n",
    "dataset = HuggingFaceDataset(\"ag_news\", None, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768f71c6",
   "metadata": {},
   "source": [
    "Separating train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0db7a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(name=\"ag_news\"):\n",
    "    dataset = load_dataset(name).shuffle(seed=0)\n",
    "    # num_labels = dataset['train'].features['label'].num_classes\n",
    "    return dataset[\"train\"], dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84b2bd6d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-7cfdffb70727>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ag_news'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-27f9b2900b7b>\u001b[0m in \u001b[0;36mget_data\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ag_news\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;31m#num_labels = dataset['train'].features['label'].num_classes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "train_data, test_data = get_data(\"ag_news\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3d37f3",
   "metadata": {},
   "source": [
    "Loading attacks?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b4bc59",
   "metadata": {},
   "source": [
    "### Step 2: Estimating covariance matrix on train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77151660",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_model(series, batch_size=10, output_hs=False, output_attentions=False):\n",
    "    # We choose to run by batches to avoid kernel death\n",
    "    tokens = tokenizer(\n",
    "        series.tolist(),\n",
    "        max_length=256,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        add_special_tokens=True,\n",
    "        return_attention_mask=True,\n",
    "    )\n",
    "    num_batches = (len(series) - 1) // batch_size + 1\n",
    "    Outputs = []\n",
    "    for batch_idx in range(num_batches):  # Next line can probably be coded way cleaner\n",
    "        window = [batch_idx * batch_size, (batch_idx + 1) * batch_size]\n",
    "        Outputs.append(\n",
    "            model(\n",
    "                input_ids=tokens[\"input_ids\"][window[0] : window[1]],\n",
    "                attention_mask=tokens[\"attention_mask\"][window[0] : window[1]],\n",
    "                token_type_ids=tokens[\"token_type_ids\"][window[0] : window[1]],\n",
    "                output_hidden_states=output_hs,\n",
    "                output_attentions=output_attentions,\n",
    "            )\n",
    "        )\n",
    "    last_layer = []\n",
    "    pred = []\n",
    "    softmax = []\n",
    "    num_batches = len(Outputs)\n",
    "    for batch_idx in range(num_batches):\n",
    "        if output_hs:\n",
    "            last_layer.append(Outputs[batch_idx].hidden_states[-1][:, 0, :])\n",
    "        pred.append(Outputs[batch_idx].logits.argmax(1))\n",
    "        softmax.append(torch.softmax(Outputs[batch_idx].logits, dim=1))\n",
    "    last_layer = torch.cat(last_layer)\n",
    "    pred = torch.cat(pred)\n",
    "    softmax = torch.cat(softmax)\n",
    "    if output_hs:\n",
    "        return last_layer, pred, softmax\n",
    "    return pred, softmax\n",
    "    # Outputs = torch.cat(outputs)\n",
    "    # return Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed40b230",
   "metadata": {},
   "source": [
    "Charging last layer outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1dadf830",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-81-0e574cfd8dc5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlast_layer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutput_hs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m### Looking into the last BERT layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcov_estimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'LW'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcov\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_mean_cov\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlast_layer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcov_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcov_estimator\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m### Computing the covariance matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "last_layer = run_model(train_data[\"text\"], output_hs=True)[\n",
    "    0\n",
    "]  ### Looking into the last model layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05bacd0",
   "metadata": {},
   "source": [
    "Missing : Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4525ad05",
   "metadata": {},
   "source": [
    "Computing covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ad0d66ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimators_dict = {\"LW\": LedoitWolf, \"OAS\": OAS, \"MCD\": MinCovDet}\n",
    "\n",
    "\n",
    "def get_mean_cov(x, estimator=\"Empirical\"):\n",
    "    mean = x.mean(0)\n",
    "    x = x.detach().numpy()\n",
    "    if estimator == \"Empirical\":\n",
    "        cov = np.cov(x)\n",
    "    else:\n",
    "        if estimator not in estimators_dict.keys():\n",
    "            return \"Wrong estimator, name must be in ['Empirical','LW','OAS','MCD',]\"\n",
    "        cov = torch.Tensor(estimators_dict[estimator]().fit(x).covariance_)\n",
    "    return mean, cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8886f8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_estimator = \"LW\"\n",
    "mean, cov = get_mean_cov(\n",
    "    last_layer, estimator=cov_estimator\n",
    ")  ### Computing the covariance matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bded94bf",
   "metadata": {},
   "source": [
    "### Step 3 : computing score on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ba8531",
   "metadata": {},
   "source": [
    "Missing : Loading attacks (linking test_data with 1{is_attack})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0156a5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "-> dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638badf5",
   "metadata": {},
   "source": [
    "Charging last layer outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "650acffd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-81-0e574cfd8dc5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlast_layer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutput_hs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m### Looking into the last BERT layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcov_estimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'LW'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcov\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_mean_cov\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlast_layer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcov_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcov_estimator\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m### Computing the covariance matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "last_layer, pred, _ = run_model(\n",
    "    test_data[\"text\"], output_hs=True\n",
    ")  ### Looking into the last model layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d92c26-19c1-40b2-b05a-be885ac35500",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mahanalobis_score(train_data, test_data, last_layer, cov_estimator=\"LW\"):\n",
    "    train_sets_idx = get_shuffle_idx(train_data)\n",
    "    Distance = []\n",
    "    for idx in train_sets_idx:\n",
    "        mean, cov = get_mean_cov(last_layer[train_sets_idx], estimator=cov_estimator)\n",
    "        Distance.append(get_mahalanobis(test_data, mean, cov))\n",
    "    Score = (\n",
    "        np.array(Distance) * -0.5 + math.log(2 * math.pi) * mean.shape[0] * -0.5\n",
    "    )  ### COMPRENDRE mean.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee704e07",
   "metadata": {},
   "source": [
    "Computing mahanalobis distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9be67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shuffles(data,split_size=0.9,num_samples=100):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e152afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sets = get_shuffles(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "190f1a15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_mahalanobis(x, mean, cov):\n",
    "    inv_cov = torch.inverse(cov)\n",
    "    dist = (x - mean) @ inv_cov @ (x - mean).T\n",
    "    return torch.diag(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "68275e27",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([157.2993, 156.8305, 159.5189, 158.5300, 157.0186, 157.2298, 157.0273,\n",
       "        157.8824, 156.4181, 156.8805, 157.2887, 157.3431, 158.4945, 158.4800,\n",
       "        157.6188, 157.0679, 158.6778, 157.9828, 158.7034, 158.1963])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for data_shuffle in test_sets:\n",
    "    dist = get_mahalanobis(last_layer, mean, cov)\n",
    "    log_likelihood = dist * -0.5 + math.log(2 * math.pi) * mean.shape[0] * -0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9aee94",
   "metadata": {},
   "source": [
    "(ici utiliser des train_set randomisés (90% du train_set à chaque fois), pour avoir différents mu,cov, ici fait pour une seul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e0b3a770",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(x, mean, cov):\n",
    "    score = (\n",
    "        get_mahalanobis(x, mean, cov) * -0.5\n",
    "        + math.log(2 * math.pi) * mean.shape[0] * -0.5\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_nlp",
   "language": "python",
   "name": "env_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
